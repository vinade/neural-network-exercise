# Neural network toolset

Este é um exercício de implementação de uma lib para criar modelos de poder treiná-los.
Vou tentar manter a parte teórica documentada, como o algoritmo do backpropagation, Adam, etc.

__Obs.:__ No momento a lib só aceita layers densamente conectadas entre sí, e sem conexões entre layers que não sejam vizinhas

## Funções de ativação

* RELU
* LeakyRELU
* Sigmoid
* Softmax
* Arctan

## Funções de Erro

* Mean Square Error
* Categorical Cross Entropy
* Binary Cross Entropy

## Otimizadores
* Adam
